{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CA2 - Notebook 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing functionality to be used below\n",
    "\n",
    "from pyspark.sql import functions as F #quickrun\n",
    "from pyspark.sql import Row #quickrun\n",
    "from pyspark.sql.types import * #quickrun\n",
    "from pyspark.sql import functions as F #quickrun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing initial CSV from Hadoop to begin analysis\n",
    "    Using the Spark lecture as a basis for import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the processes oulined in Tutorial 6 (a,b)\n",
    "\n",
    "flightPerfFilePath = \"/ca2/2016.csv\" \n",
    "\n",
    "\n",
    "# Obtain the dataset\n",
    "df2016  = spark.read.csv(flightPerfFilePath, header='true')\n",
    "df2016 .createOrReplaceTempView(\"FlightPerformance\")\n",
    "\n",
    "#Cache the  dataset \n",
    "df2016 .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA using some methodologies learned during lectures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2016-01-01|        DL|             1248|   DTW| LAX|        1935|  1935.0|      0.0|    23.0|    1958.0|   2107.0|   13.0|        2144|  2120.0|    -24.0|      0.0|             null|     0.0|           309.0|              285.0|   249.0|  1979.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1251|   ATL| GRR|        2125|  2130.0|      5.0|    13.0|    2143.0|   2315.0|    4.0|        2321|  2319.0|     -2.0|      0.0|             null|     0.0|           116.0|              109.0|    92.0|   640.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1254|   LAX| ATL|        2255|  2256.0|      1.0|    19.0|    2315.0|    542.0|    5.0|         600|   547.0|    -13.0|      0.0|             null|     0.0|           245.0|              231.0|   207.0|  1947.0|         null|         null|     null|          null|               null|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL Show\n",
    "\n",
    "spark.sql('select * from FlightPerformance').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PrintSchema to view columbns and DataTypes\n",
    "\n",
    "flightPerf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is DataFrame in PySpark?**\n",
    "\n",
    "PySpark DataFrames are tables that consist of rows and columns of data. It has a two-dimensional structure wherein every column consists of values of a particular variable while each row consists of a single set of values from each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " FL_DATE             | 2016-01-01 \n",
      " OP_CARRIER          | DL         \n",
      " OP_CARRIER_FL_NUM   | 1248       \n",
      " ORIGIN              | DTW        \n",
      " DEST                | LAX        \n",
      " CRS_DEP_TIME        | 1935       \n",
      " DEP_TIME            | 1935.0     \n",
      " DEP_DELAY           | 0.0        \n",
      " TAXI_OUT            | 23.0       \n",
      " WHEELS_OFF          | 1958.0     \n",
      " WHEELS_ON           | 2107.0     \n",
      " TAXI_IN             | 13.0       \n",
      " CRS_ARR_TIME        | 2144       \n",
      " ARR_TIME            | 2120.0     \n",
      " ARR_DELAY           | -24.0      \n",
      " CANCELLED           | 0.0        \n",
      " CANCELLATION_CODE   | null       \n",
      " DIVERTED            | 0.0        \n",
      " CRS_ELAPSED_TIME    | 309.0      \n",
      " ACTUAL_ELAPSED_TIME | 285.0      \n",
      " AIR_TIME            | 249.0      \n",
      " DISTANCE            | 1979.0     \n",
      " CARRIER_DELAY       | null       \n",
      " WEATHER_DELAY       | null       \n",
      " NAS_DELAY           | null       \n",
      " SECURITY_DELAY      | null       \n",
      " LATE_AIRCRAFT_DELAY | null       \n",
      " Unnamed: 27         | null       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying top row \n",
    "\n",
    "df2016.show(1, truncate = False, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FL_DATE', 'string'),\n",
       " ('OP_CARRIER', 'string'),\n",
       " ('OP_CARRIER_FL_NUM', 'string'),\n",
       " ('ORIGIN', 'string'),\n",
       " ('DEST', 'string'),\n",
       " ('CRS_DEP_TIME', 'string'),\n",
       " ('DEP_TIME', 'string'),\n",
       " ('DEP_DELAY', 'string'),\n",
       " ('TAXI_OUT', 'string'),\n",
       " ('WHEELS_OFF', 'string'),\n",
       " ('WHEELS_ON', 'string'),\n",
       " ('TAXI_IN', 'string'),\n",
       " ('CRS_ARR_TIME', 'string'),\n",
       " ('ARR_TIME', 'string'),\n",
       " ('ARR_DELAY', 'string'),\n",
       " ('CANCELLED', 'string'),\n",
       " ('CANCELLATION_CODE', 'string'),\n",
       " ('DIVERTED', 'string'),\n",
       " ('CRS_ELAPSED_TIME', 'string'),\n",
       " ('ACTUAL_ELAPSED_TIME', 'string'),\n",
       " ('AIR_TIME', 'string'),\n",
       " ('DISTANCE', 'string'),\n",
       " ('CARRIER_DELAY', 'string'),\n",
       " ('WEATHER_DELAY', 'string'),\n",
       " ('NAS_DELAY', 'string'),\n",
       " ('SECURITY_DELAY', 'string'),\n",
       " ('LATE_AIRCRAFT_DELAY', 'string'),\n",
       " ('Unnamed: 27', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying DataTypes\n",
    "df2016.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Querying with the DataFrame API**\n",
    "\n",
    "With DataFrames, you can start writing your queries using the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|ORIGIN|WEATHER_DELAY|\n",
      "+------+-------------+\n",
      "|   SLC|         18.0|\n",
      "|   JFK|         18.0|\n",
      "|   ORD|         18.0|\n",
      "|   ORD|         18.0|\n",
      "|   ORD|         18.0|\n",
      "|   PDX|         18.0|\n",
      "|   ORD|         18.0|\n",
      "|   SEA|         18.0|\n",
      "|   SJC|         18.0|\n",
      "|   LAX|         18.0|\n",
      "|   DAL|         18.0|\n",
      "|   AUS|         18.0|\n",
      "|   SMF|         18.0|\n",
      "|   LAX|         18.0|\n",
      "|   LGA|         18.0|\n",
      "|   FAR|         18.0|\n",
      "|   DEN|         18.0|\n",
      "|   DEN|         18.0|\n",
      "|   DAL|         18.0|\n",
      "|   LIH|         18.0|\n",
      "+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Origin with weather delay - weather delay =18\n",
    "df2016.select(\"ORIGIN\", \"WEATHER_DELAY\").filter(\"WEATHER_DELAY = 18\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|OP_CARRIER|CANCELLED|\n",
      "+----------+---------+\n",
      "|        AS|      1.0|\n",
      "|        AS|      1.0|\n",
      "|        AS|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "|        EV|      1.0|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Carrier and Cancellation - Cancelled =1\n",
    "df2016.select(\"OP_CARRIER\", \"CANCELLED\").filter(\"CANCELLED = 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[FL_DATE: string, OP_CARRIER: string, OP_CARRIER_FL_NUM: string, ORIGIN: string, DEST: string, CRS_DEP_TIME: string, DEP_TIME: string, DEP_DELAY: string, TAXI_OUT: string, WHEELS_OFF: string, WHEELS_ON: string, TAXI_IN: string, CRS_ARR_TIME: string, ARR_TIME: string, ARR_DELAY: string, CANCELLED: string, CANCELLATION_CODE: string, DIVERTED: string, CRS_ELAPSED_TIME: string, ACTUAL_ELAPSED_TIME: string, AIR_TIME: string, DISTANCE: string, CARRIER_DELAY: string, WEATHER_DELAY: string, NAS_DELAY: string, SECURITY_DELAY: string, LATE_AIRCRAFT_DELAY: string, Unnamed: 27: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using databricks display \n",
    "display(df2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5617658"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of rows - this process appears much quicker than flightPerf.count() used above\n",
    "# where processing took much longer\n",
    "df2016.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|ORIGIN|DEST|\n",
      "+------+----+\n",
      "|   DTW| LAX|\n",
      "|   MSP| LAX|\n",
      "|   CVG| LAS|\n",
      "|   CMH| LAX|\n",
      "|   LAS| LAX|\n",
      "|   DTW| LAS|\n",
      "|   ATL| LAS|\n",
      "|   HNL| LAX|\n",
      "|   ATL| LAX|\n",
      "|   SLC| LAS|\n",
      "|   DTW| LAS|\n",
      "|   MSP| LAX|\n",
      "|   ATL| LAX|\n",
      "|   MSY| LAX|\n",
      "|   MIA| LAX|\n",
      "|   SLC| LAX|\n",
      "|   MSP| LAS|\n",
      "|   MSP| LAX|\n",
      "|   SLC| LAS|\n",
      "|   DTW| LAX|\n",
      "+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the origin and destination where eyeColor like 'LA%'\n",
    "df2016.select(\"ORIGIN\", \"DEST\").filter(\"DEST like 'LA%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2016-05-24|        AA|              952|   DFW| EWR|         720|   713.0|     -7.0|    15.0|     728.0|   1137.0|    6.0|        1148|  1143.0|     -5.0|      0.0|             null|     0.0|           208.0|              210.0|   189.0|  1372.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-05-24|        AA|              955|   RDU| MIA|         615|   608.0|     -7.0|    12.0|     620.0|    800.0|    8.0|         820|   808.0|    -12.0|      0.0|             null|     0.0|           125.0|              120.0|   100.0|   700.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-05-24|        AA|              956|   MIA| RDU|        2147|  2235.0|     48.0|    14.0|    2249.0|     31.0|    6.0|        2359|    37.0|     38.0|      0.0|             null|     0.0|           132.0|              122.0|   102.0|   700.0|         38.0|          0.0|      0.0|           0.0|                0.0|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2016.sort(\"CANCELLED\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For selecting all rows, creating so i have all columns available for select when using on Graphs and ML algos\n",
    "\n",
    "#df2016 = df2016.select('FL_DATE','OP_CARRIER','OP_CARRIER_FL_NUM','ORIGIN','DEST','CRS_DEP_TIME','DEP_TIME','DEP_DELAY','TAXI_OUT','WHEELS_OFF','WHEELS_ON','TAXI_IN','CRS_ARR_TIME','ARR_TIME','ARR_DELAY','CANCELLED','CANCELLATION_CODE','DIVERTED','CRS_ELAPSED_TIME','ACTUAL_ELAPSED_TIME','AIR_TIME','DISTANCE','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY','LATE_AIRCRAFT_DELAY')\n",
    "#df2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2016-07-30|        AS|              605|   LAS| SEA|        1305|  1305.0|      0.0|    14.0|    1319.0|   1854.0|    7.0|        1535|  1901.0|     null|      0.0|             null|     1.0|           150.0|               null|    null|   867.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-07-30|        DL|             1135|   SLC| EWR|        1707|  1721.0|     14.0|    18.0|    1739.0|     23.0|    5.0|        2335|    28.0|     null|      0.0|             null|     1.0|           268.0|               null|    null|  1969.0|         null|         null|     null|          null|               null|       null|\n",
      "|2016-07-30|        DL|              968|   LGA| MSY|        1600|  2016.0|    256.0|    38.0|    2054.0|   2326.0|    4.0|        1829|  2330.0|     null|      0.0|             null|     1.0|           209.0|               null|    null|  1183.0|         null|         null|     null|          null|               null|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2016.sort(F.desc(\"DIVERTED\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing to change datatypes\n",
    "\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2016.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Dataframe Conversion using Cast Methodology - \n",
    "#Though we don’t face it in this dataset, there might be scenarios where Pyspark reads a double as integer or string, \n",
    "#In such cases, you can use the cast function to convert types.\n",
    "\n",
    "df2016 = df2016.withColumn('DISTANCE', F.col('DISTANCE').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#String converted successfully  - will convert all data once we have joined csv's\n",
    "\n",
    "df2016.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2016-01-01|        DL|             1254|   LAX| ATL|        2255|  2256.0|      1.0|    19.0|    2315.0|    542.0|    5.0|         600|   547.0|    -13.0|      0.0|             null|     0.0|           245.0|              231.0|   207.0|    1947|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1262|   LAX| JFK|        2255|  2248.0|     -7.0|    23.0|    2311.0|    650.0|   11.0|         715|   701.0|    -14.0|      0.0|             null|     0.0|           320.0|              313.0|   279.0|    2475|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1298|   LAX| KOA|        1730|  1729.0|     -1.0|    13.0|    1742.0|   2118.0|    4.0|        2116|  2122.0|      6.0|      0.0|             null|     0.0|           346.0|              353.0|   336.0|    2504|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1325|   LAX| MSY|        1100|  1055.0|     -5.0|    14.0|    1109.0|   1612.0|   10.0|        1633|  1622.0|    -11.0|      0.0|             null|     0.0|           213.0|              207.0|   183.0|    1670|         null|         null|     null|          null|               null|       null|\n",
      "|2016-01-01|        DL|             1354|   LAX| ATL|        2350|  2355.0|      5.0|    14.0|       9.0|    635.0|    6.0|         654|   641.0|    -13.0|      0.0|             null|     0.0|           244.0|              226.0|   206.0|    1947|         null|         null|     null|          null|               null|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filtering by distance > 100 miles from LAX\n",
    "\n",
    "df2016.filter((df2016.DISTANCE>100) & (df2016.ORIGIN=='LAX')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+--------------+\n",
      "|ORIGIN|OP_CARRIER|sum(CANCELLED)|max(CANCELLED)|\n",
      "+------+----------+--------------+--------------+\n",
      "|   BUR|        WN|         267.0|           1.0|\n",
      "|   JAX|        EV|          67.0|           1.0|\n",
      "|   KTN|        AS|          25.0|           1.0|\n",
      "|   MHT|        DL|           3.0|           1.0|\n",
      "|   PBI|        UA|          43.0|           1.0|\n",
      "|   ANC|        DL|           0.0|           0.0|\n",
      "|   LAX|        AA|         286.0|           1.0|\n",
      "|   LAX|        AS|          23.0|           1.0|\n",
      "|   BFL|        OO|          26.0|           1.0|\n",
      "|   EWR|        NK|           8.0|           1.0|\n",
      "|   HDN|        DL|           0.0|           0.0|\n",
      "|   PHX|        EV|           0.0|           0.0|\n",
      "|   RST|        OO|           3.0|           1.0|\n",
      "|   CHA|        OO|           9.0|           1.0|\n",
      "|   PHL|        F9|          38.0|           1.0|\n",
      "|   PVD|        EV|          69.0|           1.0|\n",
      "|   RIC|        OO|           6.0|           1.0|\n",
      "|   RSW|        EV|           1.0|           1.0|\n",
      "|   SEA|        AA|          86.0|           1.0|\n",
      "|   DAL|        WN|         645.0|           1.0|\n",
      "+------+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can use groupBy function with a spark DataFrame too. \n",
    "#Pretty much same as the pandas groupBy with the exception that you will need to import pyspark.sql.functions\n",
    "\n",
    "df2016.groupBy([\"ORIGIN\",\"OP_CARRIER\"]).agg(F.sum(\"CANCELLED\") ,F.max(\"CANCELLED\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 from HDFS\n",
    "\n",
    "flightPerfFilePath1 = \"/ca2/2017.csv\" \n",
    "\n",
    "df2017 = spark.read.csv(flightPerfFilePath, header='true')\n",
    "df2017.createOrReplaceTempView(\"FlightPerformance\")\n",
    "\n",
    "# Cache the  dataset \n",
    "#df2017.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018 from HDFS\n",
    "\n",
    "flightPerfFilePath2 = \"/ca2/2018.csv\" \n",
    "\n",
    "df2018 = spark.read.csv(flightPerfFilePath, header='true')\n",
    "df2018.createOrReplaceTempView(\"FlightPerformance\")\n",
    "\n",
    "# Cache the  dataset \n",
    "#df2018.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2017.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: string (nullable = true)\n",
      " |-- DEP_TIME: string (nullable = true)\n",
      " |-- DEP_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- ARR_TIME: string (nullable = true)\n",
      " |-- ARR_DELAY: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: string (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- CARRIER_DELAY: string (nullable = true)\n",
      " |-- WEATHER_DELAY: string (nullable = true)\n",
      " |-- NAS_DELAY: string (nullable = true)\n",
      " |-- SECURITY_DELAY: string (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: string (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2018.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Union to bring datasets together\n",
    "\n",
    "df_all = df2016.union(df2017) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Union to bring datasets together\n",
    "\n",
    "df_all = df_all.union(df2018) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16852974"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[FL_DATE: string, OP_CARRIER: string, OP_CARRIER_FL_NUM: string, ORIGIN: string, DEST: string, CRS_DEP_TIME: string, DEP_TIME: string, DEP_DELAY: string, TAXI_OUT: string, WHEELS_OFF: string, WHEELS_ON: string, TAXI_IN: string, CRS_ARR_TIME: string, ARR_TIME: string, ARR_DELAY: string, CANCELLED: string, CANCELLATION_CODE: string, DIVERTED: string, CRS_ELAPSED_TIME: string, ACTUAL_ELAPSED_TIME: string, AIR_TIME: string, DISTANCE: string, CARRIER_DELAY: string, WEATHER_DELAY: string, NAS_DELAY: string, SECURITY_DELAY: string, LATE_AIRCRAFT_DELAY: string, Unnamed: 27: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cache as we will be using this data quite a lot\n",
    "\n",
    "df_all.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages for Caching and Persistence of DataFrame\n",
    "Cost-efficient – Spark computations are very expensive hence reusing the computations are used to save cost. Time-efficient – Reusing repeated computations saves lots of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting DataTypes to numerical when possible**\n",
    "\n",
    "Also converting the flight date to timestamp as integer didn't present well when tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Times Stamp\n",
    "df_all = df_all.withColumn('FL_DATE', F.col('FL_DATE').cast(TimestampType()))\n",
    "\n",
    "#Integer\n",
    "df_all = df_all.withColumn('FOP_CARRIER_FL_NUM', F.col('OP_CARRIER_FL_NUM').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CRS_DEP_TIME', F.col('CRS_DEP_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('ARR_TIME', F.col('ARR_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('DEP_TIME', F.col('DEP_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('DEP_DELAY', F.col('DEP_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('TAXI_OUT', F.col('TAXI_OUT').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('WHEELS_OFF', F.col('WHEELS_OFF').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('WHEELS_ON', F.col('WHEELS_ON').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('TAXI_IN', F.col('TAXI_IN').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CRS_ARR_TIME', F.col('CRS_ARR_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('ARR_DELAY', F.col('ARR_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CANCELLED', F.col('CANCELLED').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CANCELLATION_CODE', F.col('CANCELLATION_CODE').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('DIVERTED', F.col('DIVERTED').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CRS_ELAPSED_TIME', F.col('CRS_ELAPSED_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('ACTUAL_ELAPSED_TIME', F.col('ACTUAL_ELAPSED_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('AIR_TIME', F.col('AIR_TIME').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('CARRIER_DELAY', F.col('CARRIER_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('WEATHER_DELAY', F.col('WEATHER_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('NAS_DELAY', F.col('NAS_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('SECURITY_DELAY', F.col('SECURITY_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('LATE_AIRCRAFT_DELAY', F.col('LATE_AIRCRAFT_DELAY').cast(IntegerType()))\n",
    "df_all = df_all.withColumn('DISTANCE', F.col('DISTANCE').cast(IntegerType())) #quickrun\n",
    "\n",
    "#quickrun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_CODE: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      " |-- NAS_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      " |-- FOP_CARRIER_FL_NUM: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>FOP_CARRIER_FL_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1248</td>\n",
       "      <td>DTW</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1935</td>\n",
       "      <td>1935</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1958</td>\n",
       "      <td>...</td>\n",
       "      <td>285</td>\n",
       "      <td>249</td>\n",
       "      <td>1979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1251</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2125</td>\n",
       "      <td>2130</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2143</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>92</td>\n",
       "      <td>640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1254</td>\n",
       "      <td>LAX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2255</td>\n",
       "      <td>2256</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2315</td>\n",
       "      <td>...</td>\n",
       "      <td>231</td>\n",
       "      <td>207</td>\n",
       "      <td>1947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1255</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1656</td>\n",
       "      <td>1700</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1712</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>173</td>\n",
       "      <td>1590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1256</td>\n",
       "      <td>BZN</td>\n",
       "      <td>MSP</td>\n",
       "      <td>900</td>\n",
       "      <td>1012</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>1115</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>121</td>\n",
       "      <td>874</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1257</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BNA</td>\n",
       "      <td>1233</td>\n",
       "      <td>1356</td>\n",
       "      <td>83</td>\n",
       "      <td>22</td>\n",
       "      <td>1418</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "      <td>214</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1257</td>\n",
       "      <td>BNA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1320</td>\n",
       "      <td>1446</td>\n",
       "      <td>86</td>\n",
       "      <td>15</td>\n",
       "      <td>1501</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1258</td>\n",
       "      <td>ATL</td>\n",
       "      <td>JAX</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1005</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1258</td>\n",
       "      <td>JAX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1145</td>\n",
       "      <td>1144</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>1156</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DL</td>\n",
       "      <td>1259</td>\n",
       "      <td>ATL</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2110</td>\n",
       "      <td>2107</td>\n",
       "      <td>-3</td>\n",
       "      <td>16</td>\n",
       "      <td>2123</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>116</td>\n",
       "      <td>761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  DEP_TIME  \\\n",
       "0 2016-01-01         DL              1248    DTW  LAX          1935      1935   \n",
       "1 2016-01-01         DL              1251    ATL  GRR          2125      2130   \n",
       "2 2016-01-01         DL              1254    LAX  ATL          2255      2256   \n",
       "3 2016-01-01         DL              1255    SLC  ATL          1656      1700   \n",
       "4 2016-01-01         DL              1256    BZN  MSP           900      1012   \n",
       "5 2016-01-01         DL              1257    ATL  BNA          1233      1356   \n",
       "6 2016-01-01         DL              1257    BNA  ATL          1320      1446   \n",
       "7 2016-01-01         DL              1258    ATL  JAX           945       946   \n",
       "8 2016-01-01         DL              1258    JAX  ATL          1145      1144   \n",
       "9 2016-01-01         DL              1259    ATL  OKC          2110      2107   \n",
       "\n",
       "   DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  ACTUAL_ELAPSED_TIME  AIR_TIME  \\\n",
       "0          0        23        1958  ...                  285       249   \n",
       "1          5        13        2143  ...                  109        92   \n",
       "2          1        19        2315  ...                  231       207   \n",
       "3          4        12        1712  ...                  193       173   \n",
       "4         72        63        1115  ...                  188       121   \n",
       "5         83        22        1418  ...                   66        38   \n",
       "6         86        15        1501  ...                   58        37   \n",
       "7          1        19        1005  ...                   67        45   \n",
       "8         -1        12        1156  ...                   63        43   \n",
       "9         -3        16        2123  ...                  137       116   \n",
       "\n",
       "   DISTANCE  CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "0      1979            NaN            NaN        NaN             NaN   \n",
       "1       640            NaN            NaN        NaN             NaN   \n",
       "2      1947            NaN            NaN        NaN             NaN   \n",
       "3      1590            NaN            NaN        NaN             NaN   \n",
       "4       874           72.0            0.0       52.0             0.0   \n",
       "5       214           43.0            0.0        0.0             0.0   \n",
       "6       214            3.0            0.0        0.0             0.0   \n",
       "7       270            NaN            NaN        NaN             NaN   \n",
       "8       270            NaN            NaN        NaN             NaN   \n",
       "9       761            NaN            NaN        NaN             NaN   \n",
       "\n",
       "   LATE_AIRCRAFT_DELAY  Unnamed: 27  FOP_CARRIER_FL_NUM  \n",
       "0                  NaN         None                1248  \n",
       "1                  NaN         None                1251  \n",
       "2                  NaN         None                1254  \n",
       "3                  NaN         None                1255  \n",
       "4                  0.0         None                1256  \n",
       "5                 40.0         None                1257  \n",
       "6                 71.0         None                1257  \n",
       "7                  NaN         None                1258  \n",
       "8                  NaN         None                1258  \n",
       "9                  NaN         None                1259  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following trick helps in displaying in pandas format in my Jupyter Notebook. The .toPandas()function \n",
    "#converts a spark dataframe into a pandas Dataframe which is easier to show.\n",
    "\n",
    "df_all.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Duplicates\n",
    "\n",
    "df_all = df_all.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_CODE: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      " |-- NAS_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      " |-- FOP_CARRIER_FL_NUM: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Standard Deviation for Outliers\n",
    "#https://deepnote.com/@rajshekar-2021/Outlier-Detection-Pyspark-069e69af-2c1d-4d4d-884a-92aad276d06f\n",
    "#https://www.advancinganalytics.co.uk/blog/2020/9/2/identifying-outliers-in-spark-30\n",
    "\n",
    "stddevdf = (df_all.groupBy(\"FL_DATE\").agg(F.stddev_pop(\"DEP_DELAY\").alias(\"DEP_DELAY_std_pop\"), F.avg(\"DEP_DELAY\").alias(\"DEP_DELAY_avg\")))\n",
    "outliersremoved = df_all.join(stddevdf, \"FL_DATE\", \"left\").filter(F.abs(F.col(\"DEP_DELAY\")-F.col(\"DEP_DELAY_avg\")) <= (F.col(\"DEP_DELAY_std_pop\")*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_CODE: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      " |-- NAS_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      " |-- FOP_CARRIER_FL_NUM: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|ORIGIN|WEATHER_DELAY|\n",
      "+------+-------------+\n",
      "|   BOS|           18|\n",
      "|   ORD|           18|\n",
      "|   DEN|           18|\n",
      "|   ORD|           18|\n",
      "|   ATL|           18|\n",
      "|   LGA|           18|\n",
      "|   HOU|           18|\n",
      "|   LIH|           18|\n",
      "|   ORD|           18|\n",
      "|   ORD|           18|\n",
      "|   FLL|           18|\n",
      "|   PHL|           18|\n",
      "|   ORF|           18|\n",
      "|   EWR|           18|\n",
      "|   AUS|           18|\n",
      "|   MIA|           18|\n",
      "|   LGA|           18|\n",
      "|   SLC|           18|\n",
      "|   SJC|           18|\n",
      "|   ATL|           18|\n",
      "+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Origin with weather delay - weather delay =18\n",
    "df_all.select(\"ORIGIN\", \"WEATHER_DELAY\").filter(\"WEATHER_DELAY = 18\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+\n",
      "|ORIGIN|DEST|DISTANCE|\n",
      "+------+----+--------+\n",
      "|   HNL| JFK|    4983|\n",
      "|   JFK| HNL|    4983|\n",
      "|   HNL| JFK|    4983|\n",
      "|   JFK| HNL|    4983|\n",
      "|   JFK| HNL|    4983|\n",
      "+------+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Origin with weather delay - weather delay =18\n",
    "df_all.select(\"ORIGIN\", \"DEST\", \"DISTANCE\").filter(\"DISTANCE > 4982\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation for ML Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofweek() function extracts day of a week by taking date as input. \n",
    "#Day of week ranges from 1 to 7. (1- Sunday , 2- Monday …… 7- Saturday)\n",
    "#https://www.datasciencemadesimple.com/get-day-of-month-day-of-year-day-of-week-from-date-in-pyspark/\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import year, month, dayofweek\n",
    "df_all = df_all.withColumn('dayOfWeek', dayofweek(col('FL_DATE')))\n",
    "df_all = df_all.withColumn('month', month(col('FL_DATE')))\n",
    "df_all = df_all.withColumn('year', year(col('FL_DATE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_CODE: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- CARRIER_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      " |-- NAS_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      " |-- FOP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if columns are created\n",
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>FOP_CARRIER_FL_NUM</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>WN</td>\n",
       "      <td>1030</td>\n",
       "      <td>RDU</td>\n",
       "      <td>BWI</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1030</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>AA</td>\n",
       "      <td>1043</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1043</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>AA</td>\n",
       "      <td>1086</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1086</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>B6</td>\n",
       "      <td>115</td>\n",
       "      <td>SYR</td>\n",
       "      <td>JFK</td>\n",
       "      <td>545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>UA</td>\n",
       "      <td>1285</td>\n",
       "      <td>IAH</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1285</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>DL</td>\n",
       "      <td>1289</td>\n",
       "      <td>LGA</td>\n",
       "      <td>PBI</td>\n",
       "      <td>1046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1289</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>WN</td>\n",
       "      <td>1335</td>\n",
       "      <td>MDW</td>\n",
       "      <td>RDU</td>\n",
       "      <td>2130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1335</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>WN</td>\n",
       "      <td>1340</td>\n",
       "      <td>BUF</td>\n",
       "      <td>BWI</td>\n",
       "      <td>1815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>B6</td>\n",
       "      <td>1383</td>\n",
       "      <td>BOS</td>\n",
       "      <td>RDU</td>\n",
       "      <td>832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1383</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>WN</td>\n",
       "      <td>1412</td>\n",
       "      <td>BNA</td>\n",
       "      <td>BWI</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1412</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  DEP_TIME  \\\n",
       "0 2016-01-24         WN              1030    RDU  BWI          2015       NaN   \n",
       "1 2016-01-25         AA              1043    EWR  ORD           730       NaN   \n",
       "2 2016-02-08         AA              1086    BOS  MIA          1705       NaN   \n",
       "3 2016-02-16         B6               115    SYR  JFK           545       NaN   \n",
       "4 2016-02-24         UA              1285    IAH  ORD          1545       NaN   \n",
       "5 2016-01-23         DL              1289    LGA  PBI          1046       NaN   \n",
       "6 2016-01-21         WN              1335    MDW  RDU          2130       NaN   \n",
       "7 2016-01-25         WN              1340    BUF  BWI          1815       NaN   \n",
       "8 2016-01-23         B6              1383    BOS  RDU           832       NaN   \n",
       "9 2016-01-24         WN              1412    BNA  BWI           840       NaN   \n",
       "\n",
       "   DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  CARRIER_DELAY  WEATHER_DELAY  \\\n",
       "0        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "1        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "2        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "3        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "4        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "5        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "6        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "7        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "8        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "9        NaN       NaN         NaN  ...            NaN            NaN   \n",
       "\n",
       "   NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  \\\n",
       "0        NaN             NaN                  NaN         None   \n",
       "1        NaN             NaN                  NaN         None   \n",
       "2        NaN             NaN                  NaN         None   \n",
       "3        NaN             NaN                  NaN         None   \n",
       "4        NaN             NaN                  NaN         None   \n",
       "5        NaN             NaN                  NaN         None   \n",
       "6        NaN             NaN                  NaN         None   \n",
       "7        NaN             NaN                  NaN         None   \n",
       "8        NaN             NaN                  NaN         None   \n",
       "9        NaN             NaN                  NaN         None   \n",
       "\n",
       "   FOP_CARRIER_FL_NUM  dayOfWeek  month  year  \n",
       "0                1030          1      1  2016  \n",
       "1                1043          2      1  2016  \n",
       "2                1086          2      2  2016  \n",
       "3                 115          3      2  2016  \n",
       "4                1285          4      2  2016  \n",
       "5                1289          7      1  2016  \n",
       "6                1335          5      1  2016  \n",
       "7                1340          2      1  2016  \n",
       "8                1383          7      1  2016  \n",
       "9                1412          1      1  2016  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if columns are correct\n",
    "df_all.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Using Logical expression\n",
    "#Here we are going to use the logical expression to filter the row. \n",
    "#Filter() function is used to filter the rows from RDD/DataFrame based on the given condition or SQL expression.\n",
    "    \n",
    "#importing module\n",
    "import pyspark\n",
    "  \n",
    "# importing sparksession from pyspark.sql\n",
    "# module\n",
    "from pyspark.sql import SparkSession\n",
    "  \n",
    "# spark library import\n",
    "import pyspark.sql.functions\n",
    "  \n",
    "# creating sparksession and giving an app name\n",
    "spark = SparkSession.builder.appName('sparkdf').getOrCreate()\n",
    "\n",
    "df_all = df_all.filter(df_all.DIVERTED != \"1\")  \n",
    "df_all = df_all.filter(df_all.CANCELLED != \"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|CANCELLED|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to see if we have any further cancelled = 1\n",
    "df_all.select(\"CANCELLED\").filter(\"CANCELLED == 1\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|DIVERTED|\n",
      "+--------+\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to see if we have any further cancelled = 1\n",
    "df_all.select(\"DIVERTED\").filter(\"DIVERTED == 1\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----+----------+-----------------+------+----+---------+--------+--------+\n",
      "|dayOfWeek|month|year|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|DEP_DELAY|AIR_TIME|DISTANCE|\n",
      "+---------+-----+----+----------+-----------------+------+----+---------+--------+--------+\n",
      "|        7|    3|2016|        AS|               62|   SIT| KTN|      -24|      38|     183|\n",
      "|        5|    3|2016|        AS|              649|   LAS| BLI|      -23|     135|     954|\n",
      "|        6|    1|2016|        DL|             1485|   LGA| MCO|      -21|     145|     950|\n",
      "|        1|    2|2016|        AA|             1350|   STT| MIA|      -20|     154|    1107|\n",
      "|        3|    1|2016|        AS|              829|   SAN| OGG|      -20|     328|    2541|\n",
      "|        5|    2|2016|        AS|               65|   PSG| JNU|      -19|      26|     123|\n",
      "|        3|    2|2016|        AS|               60|   JNU| KTN|      -19|      40|     234|\n",
      "|        7|    2|2016|        AA|             1588|   JAC| DFW|      -19|     126|    1047|\n",
      "|        7|    1|2016|        UA|             1685|   LIH| DEN|      -19|     372|    3414|\n",
      "|        2|    1|2016|        NK|              727|   LBE| FLL|      -18|     150|     980|\n",
      "|        1|    1|2016|        EV|             4392|   MKE| IAH|      -18|     154|     984|\n",
      "|        7|    2|2016|        F9|             1224|   LAS| MCO|      -18|     220|    2039|\n",
      "|        5|    2|2016|        UA|              732|   SAT| IAH|      -17|      33|     191|\n",
      "|        3|    2|2016|        DL|             1063|   SLC| BZN|      -17|      51|     347|\n",
      "|        3|    1|2016|        F9|              332|   DEN| MSP|      -17|      86|     680|\n",
      "|        6|    1|2016|        F9|             1114|   LAS| CLE|      -17|     216|    1824|\n",
      "|        1|    2|2016|        AS|              830|   HNL| SJC|      -17|     278|    2417|\n",
      "|        7|    1|2016|        EV|             2767|   GRK| DFW|      -16|      28|     134|\n",
      "|        2|    2|2016|        EV|             4367|   IAH| AEX|      -16|      32|     190|\n",
      "|        6|    1|2016|        AA|             2385|   SAT| DFW|      -16|      40|     247|\n",
      "+---------+-----+----+----------+-----------------+------+----+---------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting data to be used for ML Model\n",
    "\n",
    "df_all = df_all.select('dayOfWeek','month','year','OP_CARRIER','OP_CARRIER_FL_NUM','ORIGIN','DEST','DEP_DELAY','AIR_TIME','DISTANCE')\n",
    "df_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dayOfWeek: int, month: int, year: int, OP_CARRIER: string, OP_CARRIER_FL_NUM: string, ORIGIN: string, DEST: string, DEP_DELAY: int, AIR_TIME: int, DISTANCE: int]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machine.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16614435"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machine.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine = df_machine.dropDuplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5538145"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machine.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical Correalations**\n",
    "\n",
    "The below code was taken directly from the class Tutorial 6, to check correalations prior to encoding and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['dayOfWeek','month','year','DEP_DELAY','AIR_TIME','DISTANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  0.004830381078527836,\n",
       "  nan,\n",
       "  0.0026217256049416784,\n",
       "  0.009874313818922016,\n",
       "  0.009688651157773356],\n",
       " [None,\n",
       "  1.0,\n",
       "  nan,\n",
       "  0.01088926497737125,\n",
       "  -0.002152715727768148,\n",
       "  0.002177950017452375],\n",
       " [None, None, nan, nan, nan, nan],\n",
       " [None, None, None, 1.0, 0.023101389536391022, 0.024353345647062156],\n",
       " [None, None, None, None, 1.0, 0.9857032493741889],\n",
       " [None, None, None, None, None, 1.0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_numerical = len(numerical)\n",
    "\n",
    "corr = []\n",
    "\n",
    "for i in range(0, n_numerical):\n",
    "    temp = [None] * i\n",
    "    \n",
    "    for j in range(i, n_numerical):\n",
    "        temp.append(df_all.corr(numerical[i], numerical[j]))\n",
    "    corr.append(temp)\n",
    "    \n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_machine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding & Indexing**\n",
    "\n",
    "The process includes Category Indexing, One-Hot Encoding and VectorAssembler — a feature transformer that merges multiple columns into a vector column.\n",
    "\n",
    "The below code are taken from databricks’ official site and it indexes each categorical column using the StringIndexer, then converts the indexed categories into one-hot encoded variables. The resulting output has the binary vectors appended to the end of each row. We use the StringIndexer again to encode our labels to label indices. Next, we use the VectorAssembler to combine all the feature columns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalColumns = ['ORIGIN','DEST','OP_CARRIER']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'OP_CARRIER', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['DISTANCE','AIR_TIME']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "#assembler.setHandleInvalid(\"skip\").transform(df_machine).show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a data processing pipeline**\n",
    "\n",
    "A pipeline is very convenient to maintain the structure of the data. You push the data into the pipeline. Inside the pipeline, various operations are done, the output is used to feed the algorithm.\n",
    "For instance, one universal transformation in machine learning consists of converting a string to one hot encoder, i.e., one column by a group. One hot encoder is usually a matrix full of zeroes.\n",
    "The steps to transform the data are very similar to scikit-learn. You need to:\n",
    "\n",
    "Index the string to numeric\n",
    "Create the one hot encoder\n",
    "Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- DEP_DELAY: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df_machine)\n",
    "df_machine = pipelineModel.transform(df_machine)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df_machine = df_machine.select(selectedCols)\n",
    "df_machine.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train & Test Data**\n",
    "\n",
    "we now have features column and label column.\n",
    "Randomly split data into train and test sets, and set seed for reproducibility.\n",
    "randomSplit() splits the Data Frame randomly into train and test sets. Here I set the seed for reproducibility. 0.7 and 0.3 are weights to split the dataset given as a list and they should sum up to 1.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3856260\n",
      "Test Dataset Count: 1651263\n"
     ]
    }
   ],
   "source": [
    "#Randomly split data into train and test sets, and set seed for reproducibility.\n",
    "train, test = df_machine.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forrest Classification**\n",
    "\n",
    "Now I can import and apply random forest classifier. Random forest is a method that operates by constructing multiple decision trees during the training phase. The decision of the majority of the trees is chosen by the random forest as the final decision.\n",
    "\n",
    "It comes under supervised learning and mainly used for classification but can be used for regression as well. Random forest classifier is useful because,\n",
    "-No overfitting\n",
    "-High accuracy\n",
    "-Estimates missing data\n",
    "\n",
    "https://towardsdatascience.com/a-guide-to-exploit-random-forest-classifier-in-pyspark-46d6999cb5db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+--------------------+----------+--------------------+\n",
      "|DISTANCE|AIR_TIME|label|       rawPrediction|prediction|         probability|\n",
      "+--------+--------+-----+--------------------+----------+--------------------+\n",
      "|    1199|     153|  0.0|[6.75537850932540...|       0.0|[0.33776892546627...|\n",
      "|    1946|     282|  0.0|[6.75537850932540...|       0.0|[0.33776892546627...|\n",
      "|    1587|     210|  0.0|[6.75537850932540...|       0.0|[0.33776892546627...|\n",
      "|    1587|     217|  0.0|[6.75537850932540...|       0.0|[0.33776892546627...|\n",
      "|    1747|     232|  0.0|[6.75537850932540...|       0.0|[0.33776892546627...|\n",
      "|     907|     124|  0.0|[6.37971820682752...|       0.0|[0.31898591034137...|\n",
      "|     907|     128|  0.0|[6.37971820682752...|       0.0|[0.31898591034137...|\n",
      "|     404|      59|  0.0|[6.86508143811711...|       0.0|[0.34325407190585...|\n",
      "|     404|      60|  0.0|[6.86508143811711...|       0.0|[0.34325407190585...|\n",
      "|     404|      61|  0.0|[6.86508143811711...|       0.0|[0.34325407190585...|\n",
      "+--------+--------+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here featuresCol is the list of features of the Data Frame\n",
    "#in our case it is the features column. labelCol is the targeted feature which is labelIndex. \n",
    "#rf.fit(train) fits the random forest model to our input dataset named train. \n",
    "#rfModel.transform(test) transforms the test dataset. \n",
    "#This will add new columns to the Data Frame such as prediction, rawPrediction, and probability.\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('DISTANCE','AIR_TIME','label', 'rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We can clearly compare the actual values and predicted values with the output below.\n",
    "predictions.select(\"label\", \"prediction\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**\n",
    "\n",
    "MulticlassClassificationEvaluator is the evaluator for multi-class classifications. Since we have 2 classes (DISTANCE|AIR_TIME) we need MulticlassClassificationEvaluator. The method evaluate() is used to evaluate the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7996982374928976\n",
      "Test Error = 0.2003017625071024\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "MulticlassMetrics is an evaluator for multiclass classification in the pyspark mllib library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.82148e+05 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [4.25000e+02 2.72343e+05 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [0.00000e+00 0.00000e+00 2.69213e+05 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [0.00000e+00 0.00000e+00 1.72000e+02 1.77073e+05 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [3.86500e+03 2.00000e+00 1.04000e+02 0.00000e+00 1.56416e+05 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.22640e+05 1.72160e+04 2.36000e+02 0.00000e+00 0.00000e+00 2.06700e+03\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.27860e+04 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  7.04200e+04 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [4.42530e+04 2.14000e+02 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 8.27200e+03 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [2.13000e+02 7.80000e+01 1.07000e+02 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 4.01400e+04 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [2.58990e+04 6.94000e+02 3.06000e+02 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.02300e+03 0.00000e+00 0.00000e+00]\n",
      " [6.59000e+02 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 2.17960e+04 0.00000e+00]\n",
      " [2.04830e+04 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = predictions.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
